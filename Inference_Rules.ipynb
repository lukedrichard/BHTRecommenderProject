{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013da0e2-3418-4112-8456-645f90faa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0450e0b-0be3-436e-b31c-3f71e6eb3330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id    1    2    3    4    5    6    7    8    9  ...  1673  1674  \\\n",
       "0        1  5.0  3.0  4.0  3.0  3.0  5.0  4.0  1.0  5.0  ...   NaN   NaN   \n",
       "1        2  4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
       "2        3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
       "3        4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
       "4        5  4.0  3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
       "\n",
       "   1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1683 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('movielens_matrix.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18925b09-dbd4-418d-9fdf-fde28148db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "5     6\n",
      "6     7\n",
      "7     8\n",
      "8     9\n",
      "9    10\n",
      "Name: user id, dtype: int64\n",
      "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "users = ratings_df['user id']\n",
    "ratings_df = ratings_df.drop('user id',axis=1)\n",
    "books = ratings_df.columns\n",
    "print(users[0:10])\n",
    "print(books[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de0a6a37-33f5-47a5-b24f-43e29e546aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1      2      3      4      5      6      7      8      9     10  ...  \\\n",
       "0   True   True   True   True   True   True   True   True   True   True  ...   \n",
       "1   True  False  False  False  False  False  False  False  False   True  ...   \n",
       "2  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "3  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "4   True   True  False  False  False  False  False  False  False  False  ...   \n",
       "\n",
       "    1673   1674   1675   1676   1677   1678   1679   1680   1681   1682  \n",
       "0  False  False  False  False  False  False  False  False  False  False  \n",
       "1  False  False  False  False  False  False  False  False  False  False  \n",
       "2  False  False  False  False  False  False  False  False  False  False  \n",
       "3  False  False  False  False  False  False  False  False  False  False  \n",
       "4  False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.fillna(0, inplace=True)\n",
    "#ratings_df[ratings_df < 3] = 0\n",
    "ratings_df = ratings_df.astype(bool)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ef922-9d05-422d-8387-dd16b56a02ca",
   "metadata": {},
   "source": [
    "## Apriori/Inference Rules Algorithm from Scratch\n",
    "\n",
    "The apriori algorithm works by setting a minimum support threshhold and discarding any transaction sets which fall below this threshold. Checking all transaction sets would be copmutationally expensive. Instead, apriori checks the transaction of just one item at a time. If the single item transaction has sufficient support, then it is saved for later. We then move on to the next single element transaction. If it is sufficient, we save it for later. We then combine the single element transaction with all previously saved transaction subsets, keeping those new subsets which have sufficient support. The process is repeated for each possible item in our transactions. This allows us to find all useful transaction subsets while only passing over the data once.\n",
    "\n",
    "After finding the transactions with sufficient support, we search for suitable asociation rules, keeping only those rules which surpass a confidence threshold. To create an association rule we simply partition one of the transaction sets found previously into antecedent and consequent sets. We then calculate the confidence for this rule to determine whether we should keep it or not.\n",
    "\n",
    "#### Support\n",
    "Support quantifies how often a transaction appears in the data. This helps us to focus on only those transaction for which finding an association rule will be consequential. Support is calculated as the probability of finding the transaction subset being part of one of the given transactions.\n",
    "$$S(t) = P(t\\subseteq T) = \\frac{\\lvert t \\rvert}{\\lvert T \\rvert}$$\n",
    "\n",
    "### Confidence\n",
    "Confidence tells us what you would imagine, how confident we are that it is a good rule. Confidence is calculated as the conditional probability of the consequent happening given that the antecedent occured.\n",
    "$$C(A \\implies B) = P(B\\vert A) = \\frac{P(B\\cap A)}{P(A)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8309127c-ea3a-4f3c-a76c-6541758ec014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class apriori_rules:\n",
    "    def __init__(self, support_threshold = 0.8):\n",
    "        self.support_threshold = support_threshold\n",
    "        self.confidence_threshold = None\n",
    "        self.confidence_threshold = None\n",
    "        self.transaction_subsets = None\n",
    "        self.supported_t = None\n",
    "        self.supported_values = None\n",
    "        self.data = None\n",
    "        self.itemsets = None\n",
    "        self.rules = None\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        \n",
    "        '''Fits the transaction set. Search for transaction subset with sufficient support. \n",
    "        Save array/df of transactions and support as class attribute.\n",
    "        X, our data, is the set of transactions. It should be in the form of rows of transactions.\n",
    "        For each possible item in a transaction, there should be a column of binary values.'''\n",
    "\n",
    "        X_array = X.to_numpy()\n",
    "        self.data = X_array\n",
    "        X_transpose = X_array.T\n",
    "        #get number of transactions\n",
    "        total_transactions = X_array.shape[0]\n",
    "        #list of transactions which have sufficient support\n",
    "        self.supported_t = []\n",
    "        #list of support values for itemsets in supported_t\n",
    "        self.support_values = []\n",
    "        #dictionary to hold the chosen itemsets and their associted support values for easy access later\n",
    "        self.itemsets = {}\n",
    "        #holds indices of rows which hvae supported item sets\n",
    "        supported_rows = []\n",
    "        \n",
    "        \n",
    "        #Check each single element set, combine with prvious sets, save sufficent sets\n",
    "        for index, col in enumerate(X_transpose):\n",
    "            col_support = col.sum()/total_transactions\n",
    "            #if not enough support for single element itemset, continue since no other itemset with that item will have enough support\n",
    "            if col_support < self.support_threshold:\n",
    "                continue\n",
    "\n",
    "            #update our list of supported transactions\n",
    "            copy_supported_t = self.supported_t.copy()\n",
    "            for t in copy_supported_t:\n",
    "                mask = X_array[:, tuple(t+[index])].all(axis=1)\n",
    "                count = mask.sum()\n",
    "                itemset_support = count/total_transactions\n",
    "                if itemset_support > self.support_threshold:\n",
    "                    self.supported_t.append(t + [index])\n",
    "                    self.support_values.append((itemset_support))\n",
    "                    self.itemsets[tuple(t + [index])] = itemset_support\n",
    "             \n",
    "            #add single element itemset\n",
    "            self.supported_t.append([index])\n",
    "            self.support_values.append((col_support))\n",
    "            self.itemsets[tuple([index])] = col_support\n",
    "\n",
    "        df_dict = {'itemsets': self.supported_t, 'support':self.support_values}\n",
    "        self.transaction_subsets = pd.DataFrame(df_dict)\n",
    "\n",
    "        return\n",
    "\n",
    "    def find_rules(self, confidence_threshold=0.8):\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        #lists to hold rule information. Will be made into a DataFrame at the end\n",
    "        antecedent_list = []\n",
    "        consequent_list = []\n",
    "        support_list = []\n",
    "        confidence_list = []\n",
    "        \n",
    "        for itemset, support in self.itemsets.items():\n",
    "            if len(itemset) == 1:\n",
    "                continue\n",
    "            #get all combinations of possible combinations of antecedent -> consequent pairs\n",
    "            #get all possible antecedents of all possible lengths\n",
    "            for k in range(1,len(itemset)):\n",
    "                combs = list(combinations(itemset,k))\n",
    "                for antecedent in combs:\n",
    "                    #calculate confidence\n",
    "                    confidence = support/self.itemsets[tuple(antecedent)]\n",
    "                    if confidence >= confidence_threshold:\n",
    "                        consequent = tuple(c for c in itemset if c not in antecedent) #find consequent\n",
    "                        #save to rules dictionary\n",
    "                        antecedent_list.append(antecedent)\n",
    "                        consequent_list.append(consequent)\n",
    "                        support_list.append(support)\n",
    "                        confidence_list.append(confidence)\n",
    "            \n",
    "        #create rules dataframe\n",
    "        df_dict = {'antecedents': antecedent_list, 'consequents':consequent_list, 'support':support_list,'confidence':confidence_list}\n",
    "        self.rules = pd.DataFrame(df_dict)\n",
    "          \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0dc35ef6-c334-46d4-bf2d-557bd4b55f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        itemsets   support\n",
      "0            [0]  0.479321\n",
      "1            [3]  0.221633\n",
      "2         [0, 6]  0.297985\n",
      "3            [6]  0.415695\n",
      "4            [7]  0.232238\n",
      "...          ...       ...\n",
      "2886  [257, 747]  0.250265\n",
      "2887  [287, 747]  0.219512\n",
      "2888  [293, 747]  0.237540\n",
      "2889  [299, 747]  0.226935\n",
      "2890       [747]  0.335101\n",
      "\n",
      "[2891 rows x 2 columns]\n",
      "  antecedents consequents   support  confidence\n",
      "0        (0,)       (49,)  0.404030    0.842920\n",
      "1      (0, 6)       (49,)  0.258749    0.868327\n",
      "2        (6,)       (49,)  0.343584    0.826531\n",
      "3        (7,)       (49,)  0.200424    0.863014\n",
      "4       (10,)       (49,)  0.222694    0.889831\n"
     ]
    }
   ],
   "source": [
    "apriori_model = apriori_rules(support_threshold=0.2)\n",
    "apriori_model.fit(ratings_df)\n",
    "print(apriori_model.transaction_subsets)\n",
    "\n",
    "apriori_model.find_rules(confidence_threshold = 0.8)\n",
    "print(apriori_model.rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32e59560-34bb-458e-9b6b-8009db83cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 2)\n",
      "(7175, 4)\n"
     ]
    }
   ],
   "source": [
    "print(apriori_model.transaction_subsets.shape)\n",
    "print(apriori_model.rules.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24e692cd-7330-4fde-a313-7d007f802aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_model.rules['confidence'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6d929a5-e873-4ef7-9e02-378d2575333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1eef29b3-5956-417b-823c-b6283775aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support itemsets\n",
      "0  0.479321      (1)\n",
      "1  0.221633      (4)\n",
      "2  0.415695      (7)\n",
      "3  0.232238      (8)\n",
      "4  0.317073      (9)\n",
      "  antecedents consequents   support  confidence      lift\n",
      "0         (1)        (50)  0.404030    0.842920  1.363420\n",
      "1       (125)         (1)  0.208908    0.807377  1.684417\n",
      "2         (4)       (174)  0.200424    0.904306  2.030383\n",
      "3         (7)        (50)  0.343584    0.826531  1.336910\n",
      "4         (7)       (100)  0.339343    0.816327  1.515346\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(ratings_df, min_support=0.2, use_colnames=True)\n",
    "print(frequent_itemsets.head())\n",
    "rules = association_rules(frequent_itemsets, metric = 'confidence', min_threshold = 0.8)\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9a9efdc-9b70-4d0d-9b8b-87419a00574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 2)\n",
      "(7175, 14)\n"
     ]
    }
   ],
   "source": [
    "print(frequent_itemsets.shape)\n",
    "print(rules.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fc4d1a5-b662-4511-a719-e8298999ceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules['confidence'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcdeb8-22a8-4559-9e03-2442037bffef",
   "metadata": {},
   "source": [
    "### Make Recommendations based on uesr rating vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0deaabdf-653c-42da-b73b-bfbb197577f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 556  349 1354 1560  785 1540 1519 1529 1194  106  511 1159 1207 1546\n",
      "  831  914  440  823  529 1350 1233  368 1655 1110  509  426 1306  937\n",
      "  428  384]\n",
      "[ 106  349  368  384  426  428  440  509  511  529  556  785  823  831\n",
      "  914  937 1110 1159 1194 1207 1233 1306 1350 1354 1519 1529 1540 1546\n",
      " 1560 1655]\n",
      "[49, 171, 173]\n",
      "Index(['50', '172', '174'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "user_ratings = np.zeros(ratings_df.shape[1])\n",
    "rand_items = np.random.randint(ratings_df.shape[1], size=30)\n",
    "user_ratings[rand_items] = 1 #random user vector\n",
    "rated_items = np.argwhere(user_ratings).flatten() #column indeices of books that have been rated\n",
    "#rated_items = [21,58,64]\n",
    "print(rand_items)\n",
    "print(rated_items)\n",
    "\n",
    "mask = apriori_model.rules['antecedents'].apply(lambda a: set(a).issubset(rated_items)) #indices of antecedents that apply\n",
    "recs = apriori_model.rules.loc[mask, 'consequents'] #get matching consequents as recommendations\n",
    "recs = list(set(item for tpl in recs for item in tpl)) #make the recommendations unique\n",
    "recs = [rec for rec in recs if rec not in rated_items]#remove recommendations matching items already in user list\n",
    "book_recs = books[recs]#map recs indices back to original book names\n",
    "\n",
    "print(recs)\n",
    "print(book_recs)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb962c-a4e5-4268-8247-191010025906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
